{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhwN0XQX4Icu"
      },
      "source": [
        "# Чат-бот, использующий модели Seq2Seq LSTM\n",
        "В этом блокноте модель seq2seq LSTM, используя функциональный API Keras, чтобы создать работающего чат-бота, который отвечал бы на задаваемые ему вопросы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm5g4WIG5ym2"
      },
      "source": [
        "## 1) Импорт библотек\n",
        "\n",
        "Мы импортируем [TensorFlow](https://www.tensorflow.org ) и наш любимый [Keras](https://www.tensorflow.org/guide/keras ). Кроме того, мы импортируем другие модули, которые помогают в определении слоев модели.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UgZHR8TO0lFF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow.keras import layers , activations , models , preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxiGOLldKOQD"
      },
      "source": [
        "## 2) Предварительная обработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imkdw4os6FI4"
      },
      "source": [
        "### A) Создание датасета\n",
        "\n",
        "Из приведённого файла, создаём папку data с .yml фаёлами, названий категорий со следующей структурой.\n",
        "\n",
        "Название категории:\n",
        "- Вариант названия 1\n",
        "- Вариант названия 2\n",
        "\n",
        "Разговоры:\n",
        "- Вопрос 1?\n",
        "- - Ответ\n",
        "- Вопрос 2?\n",
        "- - Ответ\n",
        "- Вопрос 3?\n",
        "- - Ответ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF1mDKD_R6Os"
      },
      "source": [
        "### B) Считывание данных из файлов\n",
        "\n",
        "Мы анализируем каждый из файлов `.yaml`.\n",
        "\n",
        "* Соедините два или более предложений, если в ответе их два или более.\n",
        "* Удалите ненужные типы данных, которые образуются при синтаксическом анализе данных.\n",
        "* Добавьте `<START>` и `<END>` ко всем 'ответам'.\n",
        "* Создали `Токенизатор` и загрузили в него весь словарный запас (`вопросы` + `ответы`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RzTBhga6MiV7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VOCAB SIZE : 1894\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras import preprocessing , utils\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "dir_path = 'data_example'\n",
        "files_list = os.listdir(dir_path + os.sep)\n",
        "\n",
        "questions = list()\n",
        "answers = list()\n",
        "\n",
        "for filepath in files_list:\n",
        "    stream = open( dir_path + os.sep + filepath , 'rb')\n",
        "    docs = yaml.safe_load(stream)\n",
        "    conversations = docs['conversations']\n",
        "    for con in conversations:\n",
        "        if len( con ) > 2 :\n",
        "            questions.append(con[0])\n",
        "            replies = con[ 1 : ]\n",
        "            ans = ''\n",
        "            for rep in replies:\n",
        "                ans += ' ' + rep\n",
        "            answers.append( ans )\n",
        "        elif len( con )> 1:\n",
        "            questions.append(con[0])\n",
        "            answers.append(con[1])\n",
        "\n",
        "answers_with_tags = list()\n",
        "for i in range( len( answers ) ):\n",
        "    if type( answers[i] ) == str:\n",
        "        answers_with_tags.append( answers[i] )\n",
        "    else:\n",
        "        questions.pop( i )\n",
        "\n",
        "answers = list()\n",
        "for i in range( len( answers_with_tags ) ) :\n",
        "    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
        "\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts( questions + answers )\n",
        "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
        "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzsaO1YvS-M8"
      },
      "source": [
        "\n",
        "### C) Подготовка данных для модели Seq2Seq\n",
        "\n",
        "Для нашей модели требуются три массива, а именно `encoder_input_data`, `decoder_input_data` и `decoder_output_data`.\n",
        "\n",
        "Для `encoder_input_data` :\n",
        "* Обозначьте токеном `questions`. Набеитие их до максимальной длины.\n",
        "\n",
        "Для `decoder_input_data` :\n",
        "* Обозначьте токеном `answers`. Набитие их до максимальной длины.\n",
        "\n",
        "Для `decoder_output_data` :\n",
        "\n",
        "* Обозначьте токеном `answers`. Удаляем первый элемент из всех `tokenized_answers`. Это `<START>` элемент, который мы добавили ранее.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a5AD9ooQKc33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(564, 22) 22\n",
            "(564, 74) 74\n",
            "(564, 74, 1894)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from gensim.models import Word2Vec\n",
        "import re\n",
        "\n",
        "vocab = []\n",
        "for word in tokenizer.word_index:\n",
        "    vocab.append( word )\n",
        "\n",
        "def tokenize( sentences ):\n",
        "    tokens_list = []\n",
        "    vocabulary = []\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.lower()\n",
        "        sentence = re.sub( '[^a-zA-Z]', ' ', sentence )\n",
        "        tokens = sentence.split()\n",
        "        vocabulary += tokens\n",
        "        tokens_list.append( tokens )\n",
        "    return tokens_list , vocabulary\n",
        "\n",
        "#p = tokenize( questions + answers )\n",
        "#model = Word2Vec( p[ 0 ] )\n",
        "\n",
        "#embedding_matrix = np.zeros( ( VOCAB_SIZE , 100 ) )\n",
        "#for i in range( len( tokenizer.word_index ) ):\n",
        "    #embedding_matrix[ i ] = model[ vocab[i] ]\n",
        "\n",
        "# encoder_input_data\n",
        "tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
        "maxlen_questions = max( [ len(x) for x in tokenized_questions ] )\n",
        "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions , maxlen=maxlen_questions , padding='post' )\n",
        "encoder_input_data = np.array( padded_questions )\n",
        "print( encoder_input_data.shape , maxlen_questions )\n",
        "\n",
        "# decoder_input_data\n",
        "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
        "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
        "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
        "decoder_input_data = np.array( padded_answers )\n",
        "print( decoder_input_data.shape , maxlen_answers )\n",
        "\n",
        "# decoder_output_data\n",
        "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
        "for i in range(len(tokenized_answers)) :\n",
        "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
        "onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )\n",
        "decoder_output_data = np.array( onehot_answers )\n",
        "print( decoder_output_data.shape )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SwY3T139l19"
      },
      "source": [
        "## 3) Определение модели кодер-декодер\n",
        "Модель будет иметь слои встраивания, LSTM и Dense. Базовая конфигурация выглядит следующим образом.\n",
        "\n",
        "\n",
        "* 2 входных слоя : один для `encoder_input_data` и другой для `decoder_input_data`.\n",
        "* Слой встраивания: Для преобразования векторов токенов в плотные векторы фиксированного размера. ** ( Примечание: Не забудьте здесь аргумент `mask_zero=True` )**\n",
        "* Уровень LSTM: Обеспечивает доступ к долгосрочным и краткосрочным ячейкам.\n",
        "\n",
        "Работающий :\n",
        "\n",
        "1. `encoder_input_data` находится на уровне встраивания ( `encoder_embedding` ).\n",
        "2. Выходные данные слоя встраивания поступают в ячейку LSTM, которая генерирует 2 вектора состояния (`h` и `c`, которые являются `encoder_states`).\n",
        "3. Эти состояния задаются в ячейке LSTM декодера.\n",
        "4. Данные decoder_input_data поступают через уровень встраивания.\n",
        "5. Вложения выполняются в ячейку LSTM (в которой были состояния) для создания последующих действий.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-gUYtOwv21rt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 22)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 74)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 22, 200)              378800    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 74, 200)              378800    ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, 200),                320800    ['embedding[0][0]']           \n",
            "                              (None, 200),                                                        \n",
            "                              (None, 200)]                                                        \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, 74, 200),            320800    ['embedding_1[0][0]',         \n",
            "                              (None, 200),                           'lstm[0][1]',                \n",
            "                              (None, 200)]                           'lstm[0][2]']                \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 74, 1894)             380694    ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1779894 (6.79 MB)\n",
            "Trainable params: 1779894 (6.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=( maxlen_questions , ))\n",
        "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True ) (encoder_inputs)\n",
        "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n",
        "encoder_states = [ state_h , state_c ]\n",
        "\n",
        "decoder_inputs = tf.keras.layers.Input(shape=( maxlen_answers ,  ))\n",
        "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n",
        "decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n",
        "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
        "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax )\n",
        "output = decoder_dense ( decoder_outputs )\n",
        "\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9g_8sR7WWf3"
      },
      "source": [
        "## 4) Обучение модели\n",
        "Мы обучаем модель для нескольких эпох с помощью оптимизатора `RMSProp` и функции потерь `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "N74NZnfo3Id-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "19/19 [==============================] - 15s 179ms/step - loss: 7.3331\n",
            "Epoch 2/250\n",
            "19/19 [==============================] - 3s 178ms/step - loss: 6.0675\n",
            "Epoch 3/250\n",
            "19/19 [==============================] - 3s 181ms/step - loss: 5.8256\n",
            "Epoch 4/250\n",
            "19/19 [==============================] - 3s 175ms/step - loss: 5.7614\n",
            "Epoch 5/250\n",
            "19/19 [==============================] - 3s 179ms/step - loss: 5.7287\n",
            "Epoch 6/250\n",
            "19/19 [==============================] - 5s 247ms/step - loss: 5.6942\n",
            "Epoch 7/250\n",
            "19/19 [==============================] - 5s 248ms/step - loss: 5.6381\n",
            "Epoch 8/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 5.5781\n",
            "Epoch 9/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 5.5052\n",
            "Epoch 10/250\n",
            "19/19 [==============================] - 5s 243ms/step - loss: 5.4432\n",
            "Epoch 11/250\n",
            "19/19 [==============================] - 5s 245ms/step - loss: 5.3870\n",
            "Epoch 12/250\n",
            "19/19 [==============================] - 5s 263ms/step - loss: 5.3657\n",
            "Epoch 13/250\n",
            "19/19 [==============================] - 5s 265ms/step - loss: 5.3276\n",
            "Epoch 14/250\n",
            "19/19 [==============================] - 5s 271ms/step - loss: 5.3036\n",
            "Epoch 15/250\n",
            "19/19 [==============================] - 5s 258ms/step - loss: 5.2776\n",
            "Epoch 16/250\n",
            "19/19 [==============================] - 5s 276ms/step - loss: 5.2522\n",
            "Epoch 17/250\n",
            "19/19 [==============================] - 5s 267ms/step - loss: 5.2218\n",
            "Epoch 18/250\n",
            "19/19 [==============================] - 5s 268ms/step - loss: 5.1855\n",
            "Epoch 19/250\n",
            "19/19 [==============================] - 5s 264ms/step - loss: 5.1648\n",
            "Epoch 20/250\n",
            "19/19 [==============================] - 5s 276ms/step - loss: 5.1345\n",
            "Epoch 21/250\n",
            "19/19 [==============================] - 5s 273ms/step - loss: 5.1176\n",
            "Epoch 22/250\n",
            "19/19 [==============================] - 5s 266ms/step - loss: 5.0729\n",
            "Epoch 23/250\n",
            "19/19 [==============================] - 5s 253ms/step - loss: 5.0452\n",
            "Epoch 24/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 5.0043\n",
            "Epoch 25/250\n",
            "19/19 [==============================] - 5s 246ms/step - loss: 4.9823\n",
            "Epoch 26/250\n",
            "19/19 [==============================] - 5s 248ms/step - loss: 4.9458\n",
            "Epoch 27/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 4.9251\n",
            "Epoch 28/250\n",
            "19/19 [==============================] - 5s 257ms/step - loss: 4.8881\n",
            "Epoch 29/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 4.8558\n",
            "Epoch 30/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 4.8426\n",
            "Epoch 31/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 4.8018\n",
            "Epoch 32/250\n",
            "19/19 [==============================] - 5s 245ms/step - loss: 4.7637\n",
            "Epoch 33/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 4.7368\n",
            "Epoch 34/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 4.7062\n",
            "Epoch 35/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 4.6813\n",
            "Epoch 36/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 4.6597\n",
            "Epoch 37/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 4.6371\n",
            "Epoch 38/250\n",
            "19/19 [==============================] - 4s 236ms/step - loss: 4.6079\n",
            "Epoch 39/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 4.5869\n",
            "Epoch 40/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 4.5483\n",
            "Epoch 41/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 4.4975\n",
            "Epoch 42/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 4.4939\n",
            "Epoch 43/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 4.4694\n",
            "Epoch 44/250\n",
            "19/19 [==============================] - 5s 242ms/step - loss: 4.4303\n",
            "Epoch 45/250\n",
            "19/19 [==============================] - 5s 246ms/step - loss: 4.4088\n",
            "Epoch 46/250\n",
            "19/19 [==============================] - 5s 245ms/step - loss: 4.3787\n",
            "Epoch 47/250\n",
            "19/19 [==============================] - 5s 242ms/step - loss: 4.3497\n",
            "Epoch 48/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 4.3184\n",
            "Epoch 49/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 4.2923\n",
            "Epoch 50/250\n",
            "19/19 [==============================] - 5s 249ms/step - loss: 4.2718\n",
            "Epoch 51/250\n",
            "19/19 [==============================] - 5s 264ms/step - loss: 4.2451\n",
            "Epoch 52/250\n",
            "19/19 [==============================] - 5s 273ms/step - loss: 4.1917\n",
            "Epoch 53/250\n",
            "19/19 [==============================] - 5s 242ms/step - loss: 4.1954\n",
            "Epoch 54/250\n",
            "19/19 [==============================] - 5s 256ms/step - loss: 4.1533\n",
            "Epoch 55/250\n",
            "19/19 [==============================] - 5s 265ms/step - loss: 4.1400\n",
            "Epoch 56/250\n",
            "19/19 [==============================] - 5s 259ms/step - loss: 4.1126\n",
            "Epoch 57/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 4.1005\n",
            "Epoch 58/250\n",
            "19/19 [==============================] - 4s 231ms/step - loss: 4.0656\n",
            "Epoch 59/250\n",
            "19/19 [==============================] - 5s 260ms/step - loss: 4.0369\n",
            "Epoch 60/250\n",
            "19/19 [==============================] - 6s 290ms/step - loss: 4.0037\n",
            "Epoch 61/250\n",
            "19/19 [==============================] - 5s 249ms/step - loss: 3.9717\n",
            "Epoch 62/250\n",
            "19/19 [==============================] - 5s 268ms/step - loss: 3.9389\n",
            "Epoch 63/250\n",
            "19/19 [==============================] - 5s 245ms/step - loss: 3.9408\n",
            "Epoch 64/250\n",
            "19/19 [==============================] - 5s 254ms/step - loss: 3.9177\n",
            "Epoch 65/250\n",
            "19/19 [==============================] - 5s 250ms/step - loss: 3.8899\n",
            "Epoch 66/250\n",
            "19/19 [==============================] - 5s 273ms/step - loss: 3.8428\n",
            "Epoch 67/250\n",
            "19/19 [==============================] - 5s 253ms/step - loss: 3.8396\n",
            "Epoch 68/250\n",
            "19/19 [==============================] - 5s 274ms/step - loss: 3.7947\n",
            "Epoch 69/250\n",
            "19/19 [==============================] - 5s 270ms/step - loss: 3.7924\n",
            "Epoch 70/250\n",
            "19/19 [==============================] - 5s 249ms/step - loss: 3.7472\n",
            "Epoch 71/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 3.7354\n",
            "Epoch 72/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 3.6964\n",
            "Epoch 73/250\n",
            "19/19 [==============================] - 5s 236ms/step - loss: 3.6605\n",
            "Epoch 74/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 3.6417\n",
            "Epoch 75/250\n",
            "19/19 [==============================] - 4s 236ms/step - loss: 3.6284\n",
            "Epoch 76/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 3.6092\n",
            "Epoch 77/250\n",
            "19/19 [==============================] - 5s 236ms/step - loss: 3.5925\n",
            "Epoch 78/250\n",
            "19/19 [==============================] - 4s 237ms/step - loss: 3.5564\n",
            "Epoch 79/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 3.5467\n",
            "Epoch 80/250\n",
            "19/19 [==============================] - 4s 237ms/step - loss: 3.5148\n",
            "Epoch 81/250\n",
            "19/19 [==============================] - 5s 236ms/step - loss: 3.4967\n",
            "Epoch 82/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 3.4660\n",
            "Epoch 83/250\n",
            "19/19 [==============================] - 4s 236ms/step - loss: 3.4604\n",
            "Epoch 84/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 3.4125\n",
            "Epoch 85/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 3.4026\n",
            "Epoch 86/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 3.3913\n",
            "Epoch 87/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 3.3565\n",
            "Epoch 88/250\n",
            "19/19 [==============================] - 4s 238ms/step - loss: 3.3394\n",
            "Epoch 89/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 3.3168\n",
            "Epoch 90/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 3.2928\n",
            "Epoch 91/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 3.2631\n",
            "Epoch 92/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 3.2546\n",
            "Epoch 93/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 3.2358\n",
            "Epoch 94/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 3.1937\n",
            "Epoch 95/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 3.1870\n",
            "Epoch 96/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 3.1593\n",
            "Epoch 97/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 3.1320\n",
            "Epoch 98/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 3.1158\n",
            "Epoch 99/250\n",
            "19/19 [==============================] - 5s 260ms/step - loss: 3.0984\n",
            "Epoch 100/250\n",
            "19/19 [==============================] - 5s 248ms/step - loss: 3.0612\n",
            "Epoch 101/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 3.0620\n",
            "Epoch 102/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 3.0438\n",
            "Epoch 103/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 3.0203\n",
            "Epoch 104/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 3.0074\n",
            "Epoch 105/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 2.9747\n",
            "Epoch 106/250\n",
            "19/19 [==============================] - 5s 236ms/step - loss: 2.9512\n",
            "Epoch 107/250\n",
            "19/19 [==============================] - 4s 236ms/step - loss: 2.9355\n",
            "Epoch 108/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 2.9132\n",
            "Epoch 109/250\n",
            "19/19 [==============================] - 5s 249ms/step - loss: 2.8949\n",
            "Epoch 110/250\n",
            "19/19 [==============================] - 5s 243ms/step - loss: 2.8796\n",
            "Epoch 111/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 2.8453\n",
            "Epoch 112/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 2.8316\n",
            "Epoch 113/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 2.8113\n",
            "Epoch 114/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 2.7927\n",
            "Epoch 115/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 2.7554\n",
            "Epoch 116/250\n",
            "19/19 [==============================] - 5s 243ms/step - loss: 2.7504\n",
            "Epoch 117/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 2.7297\n",
            "Epoch 118/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 2.7093\n",
            "Epoch 119/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 2.6911\n",
            "Epoch 120/250\n",
            "19/19 [==============================] - 4s 236ms/step - loss: 2.6648\n",
            "Epoch 121/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 2.6438\n",
            "Epoch 122/250\n",
            "19/19 [==============================] - 4s 234ms/step - loss: 2.6159\n",
            "Epoch 123/250\n",
            "19/19 [==============================] - 4s 234ms/step - loss: 2.6057\n",
            "Epoch 124/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 2.5950\n",
            "Epoch 125/250\n",
            "19/19 [==============================] - 4s 236ms/step - loss: 2.5783\n",
            "Epoch 126/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 2.5583\n",
            "Epoch 127/250\n",
            "19/19 [==============================] - 5s 250ms/step - loss: 2.5483\n",
            "Epoch 128/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 2.5080\n",
            "Epoch 129/250\n",
            "19/19 [==============================] - 4s 231ms/step - loss: 2.4891\n",
            "Epoch 130/250\n",
            "19/19 [==============================] - 4s 230ms/step - loss: 2.4722\n",
            "Epoch 131/250\n",
            "19/19 [==============================] - 4s 233ms/step - loss: 2.4567\n",
            "Epoch 132/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 2.4432\n",
            "Epoch 133/250\n",
            "19/19 [==============================] - 5s 263ms/step - loss: 2.4254\n",
            "Epoch 134/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 2.3957\n",
            "Epoch 135/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 2.3894\n",
            "Epoch 136/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 2.3656\n",
            "Epoch 137/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 2.3481\n",
            "Epoch 138/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 2.3293\n",
            "Epoch 139/250\n",
            "19/19 [==============================] - 5s 255ms/step - loss: 2.3019\n",
            "Epoch 140/250\n",
            "19/19 [==============================] - 5s 261ms/step - loss: 2.2900\n",
            "Epoch 141/250\n",
            "19/19 [==============================] - 4s 234ms/step - loss: 2.2759\n",
            "Epoch 142/250\n",
            "19/19 [==============================] - 4s 237ms/step - loss: 2.2512\n",
            "Epoch 143/250\n",
            "19/19 [==============================] - 5s 236ms/step - loss: 2.2429\n",
            "Epoch 144/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 2.2092\n",
            "Epoch 145/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 2.2070\n",
            "Epoch 146/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 2.1851\n",
            "Epoch 147/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 2.1645\n",
            "Epoch 148/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 2.1418\n",
            "Epoch 149/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 2.1414\n",
            "Epoch 150/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 2.1135\n",
            "Epoch 151/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 2.0920\n",
            "Epoch 152/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 2.0844\n",
            "Epoch 153/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 2.0604\n",
            "Epoch 154/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 2.0478\n",
            "Epoch 155/250\n",
            "19/19 [==============================] - 4s 236ms/step - loss: 2.0360\n",
            "Epoch 156/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 2.0064\n",
            "Epoch 157/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 1.9881\n",
            "Epoch 158/250\n",
            "19/19 [==============================] - 5s 236ms/step - loss: 1.9790\n",
            "Epoch 159/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 1.9710\n",
            "Epoch 160/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 1.9482\n",
            "Epoch 161/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 1.9348\n",
            "Epoch 162/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 1.9150\n",
            "Epoch 163/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 1.8848\n",
            "Epoch 164/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 1.8745\n",
            "Epoch 165/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 1.8690\n",
            "Epoch 166/250\n",
            "19/19 [==============================] - 5s 235ms/step - loss: 1.8532\n",
            "Epoch 167/250\n",
            "19/19 [==============================] - 5s 242ms/step - loss: 1.8218\n",
            "Epoch 168/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 1.8218\n",
            "Epoch 169/250\n",
            "19/19 [==============================] - 5s 243ms/step - loss: 1.7960\n",
            "Epoch 170/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 1.7829\n",
            "Epoch 171/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 1.7604\n",
            "Epoch 172/250\n",
            "19/19 [==============================] - 4s 236ms/step - loss: 1.7656\n",
            "Epoch 173/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 1.7407\n",
            "Epoch 174/250\n",
            "19/19 [==============================] - 4s 238ms/step - loss: 1.7132\n",
            "Epoch 175/250\n",
            "19/19 [==============================] - 5s 242ms/step - loss: 1.7108\n",
            "Epoch 176/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 1.6917\n",
            "Epoch 177/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 1.6790\n",
            "Epoch 178/250\n",
            "19/19 [==============================] - 5s 243ms/step - loss: 1.6696\n",
            "Epoch 179/250\n",
            "19/19 [==============================] - 5s 249ms/step - loss: 1.6545\n",
            "Epoch 180/250\n",
            "19/19 [==============================] - 5s 259ms/step - loss: 1.6400\n",
            "Epoch 181/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 1.6119\n",
            "Epoch 182/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 1.6084\n",
            "Epoch 183/250\n",
            "19/19 [==============================] - 4s 233ms/step - loss: 1.5910\n",
            "Epoch 184/250\n",
            "19/19 [==============================] - 5s 242ms/step - loss: 1.5762\n",
            "Epoch 185/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 1.5580\n",
            "Epoch 186/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 1.5462\n",
            "Epoch 187/250\n",
            "19/19 [==============================] - 5s 248ms/step - loss: 1.5313\n",
            "Epoch 188/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 1.5206\n",
            "Epoch 189/250\n",
            "19/19 [==============================] - 4s 236ms/step - loss: 1.5032\n",
            "Epoch 190/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 1.4909\n",
            "Epoch 191/250\n",
            "19/19 [==============================] - 4s 236ms/step - loss: 1.4799\n",
            "Epoch 192/250\n",
            "19/19 [==============================] - 5s 236ms/step - loss: 1.4602\n",
            "Epoch 193/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 1.4571\n",
            "Epoch 194/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 1.4311\n",
            "Epoch 195/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 1.4165\n",
            "Epoch 196/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 1.4155\n",
            "Epoch 197/250\n",
            "19/19 [==============================] - 4s 234ms/step - loss: 1.3993\n",
            "Epoch 198/250\n",
            "19/19 [==============================] - 5s 245ms/step - loss: 1.3824\n",
            "Epoch 199/250\n",
            "19/19 [==============================] - 5s 253ms/step - loss: 1.3757\n",
            "Epoch 200/250\n",
            "19/19 [==============================] - 5s 245ms/step - loss: 1.3595\n",
            "Epoch 201/250\n",
            "19/19 [==============================] - 5s 236ms/step - loss: 1.3462\n",
            "Epoch 202/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 1.3281\n",
            "Epoch 203/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 1.3222\n",
            "Epoch 204/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 1.3097\n",
            "Epoch 205/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 1.2963\n",
            "Epoch 206/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 1.2896\n",
            "Epoch 207/250\n",
            "19/19 [==============================] - 4s 236ms/step - loss: 1.2692\n",
            "Epoch 208/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 1.2609\n",
            "Epoch 209/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 1.2567\n",
            "Epoch 210/250\n",
            "19/19 [==============================] - 5s 236ms/step - loss: 1.2389\n",
            "Epoch 211/250\n",
            "19/19 [==============================] - 4s 236ms/step - loss: 1.2233\n",
            "Epoch 212/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 1.2103\n",
            "Epoch 213/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 1.2074\n",
            "Epoch 214/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 1.1863\n",
            "Epoch 215/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 1.1819\n",
            "Epoch 216/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 1.1593\n",
            "Epoch 217/250\n",
            "19/19 [==============================] - 4s 235ms/step - loss: 1.1569\n",
            "Epoch 218/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 1.1475\n",
            "Epoch 219/250\n",
            "19/19 [==============================] - 5s 243ms/step - loss: 1.1321\n",
            "Epoch 220/250\n",
            "19/19 [==============================] - 5s 268ms/step - loss: 1.1188\n",
            "Epoch 221/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 1.1173\n",
            "Epoch 222/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 1.1065\n",
            "Epoch 223/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 1.0945\n",
            "Epoch 224/250\n",
            "19/19 [==============================] - 5s 236ms/step - loss: 1.0757\n",
            "Epoch 225/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 1.0689\n",
            "Epoch 226/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 1.0586\n",
            "Epoch 227/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 1.0465\n",
            "Epoch 228/250\n",
            "19/19 [==============================] - 4s 234ms/step - loss: 1.0417\n",
            "Epoch 229/250\n",
            "19/19 [==============================] - 5s 241ms/step - loss: 1.0306\n",
            "Epoch 230/250\n",
            "19/19 [==============================] - 4s 237ms/step - loss: 1.0246\n",
            "Epoch 231/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 1.0098\n",
            "Epoch 232/250\n",
            "19/19 [==============================] - 5s 253ms/step - loss: 1.0013\n",
            "Epoch 233/250\n",
            "19/19 [==============================] - 5s 237ms/step - loss: 0.9869\n",
            "Epoch 234/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 0.9884\n",
            "Epoch 235/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 0.9720\n",
            "Epoch 236/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 0.9590\n",
            "Epoch 237/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 0.9579\n",
            "Epoch 238/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 0.9477\n",
            "Epoch 239/250\n",
            "19/19 [==============================] - 5s 239ms/step - loss: 0.9321\n",
            "Epoch 240/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 0.9287\n",
            "Epoch 241/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 0.9159\n",
            "Epoch 242/250\n",
            "19/19 [==============================] - 5s 240ms/step - loss: 0.9006\n",
            "Epoch 243/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 0.8960\n",
            "Epoch 244/250\n",
            "19/19 [==============================] - 4s 236ms/step - loss: 0.8915\n",
            "Epoch 245/250\n",
            "19/19 [==============================] - 5s 244ms/step - loss: 0.8767\n",
            "Epoch 246/250\n",
            "19/19 [==============================] - 6s 315ms/step - loss: 0.8697\n",
            "Epoch 247/250\n",
            "19/19 [==============================] - 5s 252ms/step - loss: 0.8605\n",
            "Epoch 248/250\n",
            "19/19 [==============================] - 5s 248ms/step - loss: 0.8533\n",
            "Epoch 249/250\n",
            "19/19 [==============================] - 5s 238ms/step - loss: 0.8387\n",
            "Epoch 250/250\n",
            "19/19 [==============================] - 5s 251ms/step - loss: 0.8364\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=30, epochs=250)\n",
        "model.save( 'model.h5' )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sOLQr0M-lAe"
      },
      "source": [
        "## 5) Определение моделей логического вывода\n",
        "Мы создали модели логического вывода, которые помогают предсказывать ответы.\n",
        "\n",
        "**Модель вывода кодера** : Принимает вопрос в качестве входных данных и выводит состояния LSTM ( `h` и `c`).\n",
        "\n",
        "**Модель вывода декодера** : Принимает 2 входных сигнала, один из которых - состояния LSTM ( выходные данные модели кодера ), второй - последовательности ввода ответа ( те, которые не имеют тега `<start>`). Он выведет ответы на вопрос, который мы ввели в модель кодера, и значения ее состояния."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1u5DE4qo3Mf2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_inference_models():\n",
        "\n",
        "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
        "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
        "\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        decoder_embedding , initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h, state_c]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = tf.keras.models.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "\n",
        "    return encoder_model , decoder_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxZp0ZRy-6dA"
      },
      "source": [
        "## 6) Общение с нашим чат-ботом\n",
        "\n",
        "Сначала мы определяем метод `str_to_tokens`, который преобразует вопросы `str` в целочисленные токены с заполнением."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5P_wDD554q9O"
      },
      "outputs": [],
      "source": [
        "\n",
        "def str_to_tokens( sentence : str ):\n",
        "    words = sentence.lower().split()\n",
        "    tokens_list = list()\n",
        "    for word in words:\n",
        "        tokens_list.append( tokenizer.word_index[ word ] )\n",
        "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djEPrfJBmZE-"
      },
      "source": [
        "1. Сначала мы берем вопрос в качестве входных данных и прогнозируем значения состояния, используя `enc_model`.\n",
        "2. Мы устанавливаем значения состояния в LSTM декодера.\n",
        "3. Затем мы генерируем последовательность, которая содержит элемент `<start>`.\n",
        "4. Мы вводим эту последовательность в `dec_model`.\n",
        "5. Мы заменяем элемент `<start>` элементом, который был предсказан `dec_model`, и обновляем значения состояния.\n",
        "6. Мы повторяем описанные выше шаги итеративно, пока не дойдем до тега `<end>` или максимальной длины ответа."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2zBmN8qB3O-e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            " standard standard entity is socialism across attached attached glad myself nasa irreverent leo leo get lightbulb all caused lightbulb lightbulb all caused guiltier guiltier waves nine investment investment dont dont small avoiding avoiding androids field godzilla godzilla idea bilbo beverages felt h2o godzilla godzilla h2o godzilla files parts express ultrasonic ultrasonic american brothers brothers awesome awesome wealth wealth variable deleted conversation component odd odd no earth earth upload flaws wilson invitation implements implements implements implements\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            " i private 1963 being japanese japanese story spray especially reason uptight national write unit admonition our sort subjects descriptive emotions bend cross cross and background particle immortal context electronic reprogrammable agent malli diagnosis questions milk proof listen unix edition governed pennsylvania few brightest xfind philip thanks identified periods orbit profit h2o people's last critical grew certainly periods profit odd omnipotent odd margin require hurt crazy 3 crazy because position primitive produce pc author employed employed\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            " mumble misses okay unit appears next appears that generally sci believe god give original ownership accept don't players macos commonly there wrote sun night spray face painted fell lem scientific provably pun seems provably beat beat hypothetical hypothetical hypothetical consume character milky science science pothead resemblance difficult write multithreaded multithreaded multithreaded reside reside reside allowed ideas club numerical wavelength wavelength fine fine interesting material sales incapable refused andes andes andes andes 20th hp bend here\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m decoded_translation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m stop_condition :\n\u001b[1;32m---> 10\u001b[0m     dec_outputs , h , c \u001b[39m=\u001b[39m dec_model\u001b[39m.\u001b[39;49mpredict([ empty_target_seq ] \u001b[39m+\u001b[39;49m states_values )\n\u001b[0;32m     11\u001b[0m     sampled_word_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax( dec_outputs[\u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :] )\n\u001b[0;32m     12\u001b[0m     sampled_word \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2521\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2512\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m   2513\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2514\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2515\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2518\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   2519\u001b[0m         )\n\u001b[1;32m-> 2521\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[0;32m   2522\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m   2523\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2524\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[0;32m   2525\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m   2526\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   2527\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2528\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2529\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2530\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2531\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[0;32m   2532\u001b[0m )\n\u001b[0;32m   2534\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2535\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1678\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1676\u001b[0m         \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1677\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1678\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1285\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[0;32m   1282\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[0;32m   1284\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[0;32m   1286\u001b[0m     x,\n\u001b[0;32m   1287\u001b[0m     y,\n\u001b[0;32m   1288\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1289\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1290\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[0;32m   1291\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1292\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1293\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1294\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1295\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1296\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[0;32m   1297\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1298\u001b[0m     pss_evaluation_shards\u001b[39m=\u001b[39;49mpss_evaluation_shards,\n\u001b[0;32m   1299\u001b[0m )\n\u001b[0;32m   1301\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[0;32m   1303\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:296\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shuffle \u001b[39m=\u001b[39m shuffle\n\u001b[0;32m    285\u001b[0m \u001b[39m# Vectorized version of shuffle.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39m# This is a performance improvement over using `from_tensor_slices`.\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[39m# The indices of the data are shuffled and batched, and these indices\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39m# 4. optimized permutation batching\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[39m# 5. disabled static optimizations\u001b[39;00m\n\u001b[1;32m--> 296\u001b[0m indices_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mrange(\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    297\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    298\u001b[0m     indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39mrepeat(epochs)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1016\u001b[0m, in \u001b[0;36mDatasetV2.range\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1012\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> range_op ->\u001b[39;00m\n\u001b[0;32m   1013\u001b[0m \u001b[39m# -> dataset_ops).\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m range_op\n\u001b[1;32m-> 1016\u001b[0m \u001b[39mreturn\u001b[39;00m range_op\u001b[39m.\u001b[39;49m_range(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\range_op.py:25\u001b[0m, in \u001b[0;36m_range\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_range\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):  \u001b[39m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m   \u001b[39mreturn\u001b[39;00m _RangeDataset(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\range_op.py:35\u001b[0m, in \u001b[0;36m_RangeDataset.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_args(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_structure \u001b[39m=\u001b[39m tensor_spec\u001b[39m.\u001b[39mTensorSpec([], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_type)\n\u001b[1;32m---> 35\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49mrange_dataset(\n\u001b[0;32m     36\u001b[0m     start\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_start,\n\u001b[0;32m     37\u001b[0m     stop\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stop,\n\u001b[0;32m     38\u001b[0m     step\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step,\n\u001b[0;32m     39\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_common_args)\n\u001b[0;32m     40\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(variant_tensor)\n",
            "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:6221\u001b[0m, in \u001b[0;36mrange_dataset\u001b[1;34m(start, stop, step, output_types, output_shapes, metadata, replicate_on_split, name)\u001b[0m\n\u001b[0;32m   6219\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   6220\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 6221\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   6222\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mRangeDataset\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, start, stop, step, \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   6223\u001b[0m       output_types, \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes, \u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m, metadata,\n\u001b[0;32m   6224\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mreplicate_on_split\u001b[39;49m\u001b[39m\"\u001b[39;49m, replicate_on_split)\n\u001b[0;32m   6225\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   6226\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "enc_model , dec_model = make_inference_models()\n",
        "\n",
        "for _ in range(10):\n",
        "    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
        "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "    while not stop_condition :\n",
        "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
        "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
        "        sampled_word = None\n",
        "        for word , index in tokenizer.word_index.items() :\n",
        "            if sampled_word_index == index :\n",
        "                decoded_translation += ' {}'.format( word )\n",
        "                sampled_word = word\n",
        "\n",
        "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
        "            stop_condition = True\n",
        "\n",
        "        empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
        "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "        states_values = [ h , c ]\n",
        "\n",
        "    print( decoded_translation )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I4BtgwsgxNk"
      },
      "source": [
        "## 7) Преобразование в TFLite (опционально)\n",
        "\n",
        "Мы можем преобразовать нашу модель seq2seq в модель TensorFlow Lite, чтобы использовать ее на периферийных устройствах."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOS0M0uLhxN5"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install tf-nightly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT8tyvpuhBOr"
      },
      "outputs": [],
      "source": [
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model( enc_model )\n",
        "buffer = converter.convert()\n",
        "open( 'enc_model.tflite' , 'wb' ).write( buffer )\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model( dec_model )\n",
        "open( 'dec_model.tflite' , 'wb' ).write( buffer )\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
