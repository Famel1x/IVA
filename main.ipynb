{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhwN0XQX4Icu"
      },
      "source": [
        "# Чат-бот, использующий модели Seq2Seq LSTM\n",
        "В этом блокноте модель seq2seq LSTM, используя функциональный API Keras, чтобы создать работающего чат-бота, который отвечал бы на задаваемые ему вопросы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm5g4WIG5ym2"
      },
      "source": [
        "## 1) Импорт библотек\n",
        "\n",
        "Мы импортируем [TensorFlow](https://www.tensorflow.org ) и наш любимый [Keras](https://www.tensorflow.org/guide/keras ). Кроме того, мы импортируем другие модули, которые помогают в определении слоев модели.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UgZHR8TO0lFF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow.keras import layers , activations , models , preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxiGOLldKOQD"
      },
      "source": [
        "## 2) Предварительная обработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imkdw4os6FI4"
      },
      "source": [
        "### A) Создание датасета\n",
        "\n",
        "Из приведённого файла, создаём папку data с .yml фаёлами, названий категорий со следующей структурой.\n",
        "\n",
        "Название категории:\n",
        "- Вариант названия 1\n",
        "- Вариант названия 2\n",
        "\n",
        "Разговоры:\n",
        "- Вопрос 1?\n",
        "- - Ответ\n",
        "- Вопрос 2?\n",
        "- - Ответ\n",
        "- Вопрос 3?\n",
        "- - Ответ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF1mDKD_R6Os"
      },
      "source": [
        "### B) Считывание данных из файлов\n",
        "\n",
        "Мы анализируем каждый из файлов `.yaml`.\n",
        "\n",
        "* Соедините два или более предложений, если в ответе их два или более.\n",
        "* Удалите ненужные типы данных, которые образуются при синтаксическом анализе данных.\n",
        "* Добавьте `<START>` и `<END>` ко всем 'ответам'.\n",
        "* Создали `Токенизатор` и загрузили в него весь словарный запас (`вопросы` + `ответы`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RzTBhga6MiV7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VOCAB SIZE : 2766\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras import preprocessing , utils\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "dir_path = 'model/chatbot_nlp/data'\n",
        "files_list = os.listdir(dir_path + os.sep)\n",
        "\n",
        "questions = list()\n",
        "answers = list()\n",
        "\n",
        "for filepath in files_list:\n",
        "    stream = open( dir_path + os.sep + filepath , 'rb')\n",
        "    docs = yaml.safe_load(stream)\n",
        "    conversations = docs['conversations']\n",
        "    for con in conversations:\n",
        "        if len( con ) > 2 :\n",
        "            questions.append(con[0])\n",
        "            replies = con[ 1 : ]\n",
        "            ans = ''\n",
        "            for rep in replies:\n",
        "                ans += ' ' + rep\n",
        "            answers.append( ans )\n",
        "        elif len( con )> 1:\n",
        "            questions.append(con[0])\n",
        "            answers.append(con[1])\n",
        "\n",
        "answers_with_tags = list()\n",
        "for i in range( len( answers ) ):\n",
        "    if type( answers[i] ) == str:\n",
        "        answers_with_tags.append( answers[i] )\n",
        "    else:\n",
        "        questions.pop( i )\n",
        "\n",
        "answers = list()\n",
        "for i in range( len( answers_with_tags ) ) :\n",
        "    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
        "\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts( questions + answers )\n",
        "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
        "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzsaO1YvS-M8"
      },
      "source": [
        "\n",
        "### C) Подготовка данных для модели Seq2Seq\n",
        "\n",
        "Для нашей модели требуются три массива, а именно `encoder_input_data`, `decoder_input_data` и `decoder_output_data`.\n",
        "\n",
        "Для `encoder_input_data` :\n",
        "* Обозначьте токеном `questions`. Набеитие их до максимальной длины.\n",
        "\n",
        "Для `decoder_input_data` :\n",
        "* Обозначьте токеном `answers`. Набитие их до максимальной длины.\n",
        "\n",
        "Для `decoder_output_data` :\n",
        "\n",
        "* Обозначьте токеном `answers`. Удаляем первый элемент из всех `tokenized_answers`. Это `<START>` элемент, который мы добавили ранее.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "a5AD9ooQKc33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(485, 31) 31\n",
            "(485, 175) 175\n",
            "(485, 175, 2766)\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import re\n",
        "\n",
        "vocab = []\n",
        "for word in tokenizer.word_index:\n",
        "    vocab.append( word )\n",
        "\n",
        "def tokenize( sentences ):\n",
        "    tokens_list = []\n",
        "    vocabulary = []\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.lower()\n",
        "        sentence = re.sub( '[^a-zA-Z]', ' ', sentence )\n",
        "        tokens = sentence.split()\n",
        "        vocabulary += tokens\n",
        "        tokens_list.append( tokens )\n",
        "    return tokens_list , vocabulary\n",
        "\n",
        "#p = tokenize( questions + answers )\n",
        "#model = Word2Vec( p[ 0 ] )\n",
        "\n",
        "#embedding_matrix = np.zeros( ( VOCAB_SIZE , 100 ) )\n",
        "#for i in range( len( tokenizer.word_index ) ):\n",
        "    #embedding_matrix[ i ] = model[ vocab[i] ]\n",
        "\n",
        "# encoder_input_data\n",
        "tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
        "maxlen_questions = max( [ len(x) for x in tokenized_questions ] )\n",
        "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions , maxlen=maxlen_questions , padding='post' )\n",
        "encoder_input_data = np.array( padded_questions )\n",
        "print( encoder_input_data.shape , maxlen_questions )\n",
        "\n",
        "# decoder_input_data\n",
        "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
        "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
        "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
        "decoder_input_data = np.array( padded_answers )\n",
        "print( decoder_input_data.shape , maxlen_answers )\n",
        "\n",
        "# decoder_output_data\n",
        "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
        "for i in range(len(tokenized_answers)) :\n",
        "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
        "onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )\n",
        "decoder_output_data = np.array( onehot_answers )\n",
        "print( decoder_output_data.shape )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SwY3T139l19"
      },
      "source": [
        "## 3) Определение модели кодер-декодер\n",
        "Модель будет иметь слои встраивания, LSTM и Dense. Базовая конфигурация выглядит следующим образом.\n",
        "\n",
        "\n",
        "* 2 входных слоя : один для `encoder_input_data` и другой для `decoder_input_data`.\n",
        "* Слой встраивания: Для преобразования векторов токенов в плотные векторы фиксированного размера. ** ( Примечание: Не забудьте здесь аргумент `mask_zero=True` )**\n",
        "* Уровень LSTM: Обеспечивает доступ к долгосрочным и краткосрочным ячейкам.\n",
        "\n",
        "Работающий :\n",
        "\n",
        "1. `encoder_input_data` находится на уровне встраивания ( `encoder_embedding` ).\n",
        "2. Выходные данные слоя встраивания поступают в ячейку LSTM, которая генерирует 2 вектора состояния (`h` и `c`, которые являются `encoder_states`).\n",
        "3. Эти состояния задаются в ячейке LSTM декодера.\n",
        "4. Данные decoder_input_data поступают через уровень встраивания.\n",
        "5. Вложения выполняются в ячейку LSTM (в которой были состояния) для создания последующих действий.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-gUYtOwv21rt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 31)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 175)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 31, 200)              553200    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 175, 200)             553200    ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, 200),                320800    ['embedding[0][0]']           \n",
            "                              (None, 200),                                                        \n",
            "                              (None, 200)]                                                        \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, 175, 200),           320800    ['embedding_1[0][0]',         \n",
            "                              (None, 200),                           'lstm[0][1]',                \n",
            "                              (None, 200)]                           'lstm[0][2]']                \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 175, 2766)            555966    ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2303966 (8.79 MB)\n",
            "Trainable params: 2303966 (8.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=( maxlen_questions , ))\n",
        "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True ) (encoder_inputs)\n",
        "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n",
        "encoder_states = [ state_h , state_c ]\n",
        "\n",
        "decoder_inputs = tf.keras.layers.Input(shape=( maxlen_answers ,  ))\n",
        "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n",
        "decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n",
        "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
        "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax )\n",
        "output = decoder_dense ( decoder_outputs )\n",
        "\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9g_8sR7WWf3"
      },
      "source": [
        "## 4) Обучение модели\n",
        "Мы обучаем модель для нескольких эпох с помощью оптимизатора `RMSProp` и функции потерь `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "N74NZnfo3Id-"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "No file or directory found at 16_model",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;32mc:\\Project\\IVA\\main.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Project/IVA/main.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=30, epochs=10)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Project/IVA/main.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# model.save( 'model1' )\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Project/IVA/main.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_loaded \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39m16_model\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\yato\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[0;32m    231\u001b[0m         filepath,\n\u001b[0;32m    232\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[0;32m    233\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[0;32m    234\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[0;32m    235\u001b[0m     )\n\u001b[0;32m    237\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m    239\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39;49mcustom_objects, \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    240\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\yato\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\yato\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 234\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[0;32m    235\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m         )\n\u001b[0;32m    238\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    239\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[0;32m    240\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[0;32m    241\u001b[0m         )\n",
            "\u001b[1;31mOSError\u001b[0m: No file or directory found at 16_model"
          ]
        }
      ],
      "source": [
        "\n",
        "# model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=30, epochs=10)\n",
        "# model.save( 'model1' )\n",
        "model_loaded = tf.keras.models.load_model('16_model')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sOLQr0M-lAe"
      },
      "source": [
        "## 5) Определение моделей логического вывода\n",
        "Мы создали модели логического вывода, которые помогают предсказывать ответы.\n",
        "\n",
        "**Модель вывода кодера** : Принимает вопрос в качестве входных данных и выводит состояния LSTM ( `h` и `c`).\n",
        "\n",
        "**Модель вывода декодера** : Принимает 2 входных сигнала, один из которых - состояния LSTM ( выходные данные модели кодера ), второй - последовательности ввода ответа ( те, которые не имеют тега `<start>`). Он выведет ответы на вопрос, который мы ввели в модель кодера, и значения ее состояния."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1u5DE4qo3Mf2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_inference_models():\n",
        "\n",
        "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
        "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
        "\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        decoder_embedding , initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h, state_c]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = tf.keras.models.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "\n",
        "    return encoder_model , decoder_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxZp0ZRy-6dA"
      },
      "source": [
        "## 6) Общение с нашим чат-ботом\n",
        "\n",
        "Сначала мы определяем метод `str_to_tokens`, который преобразует вопросы `str` в целочисленные токены с заполнением."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5P_wDD554q9O"
      },
      "outputs": [],
      "source": [
        "\n",
        "def str_to_tokens( sentence : str ):\n",
        "    words = sentence.lower().split()\n",
        "    tokens_list = list()\n",
        "    for word in words:\n",
        "        tokens_list.append( tokenizer.word_index[ word ] )\n",
        "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djEPrfJBmZE-"
      },
      "source": [
        "1. Сначала мы берем вопрос в качестве входных данных и прогнозируем значения состояния, используя `enc_model`.\n",
        "2. Мы устанавливаем значения состояния в LSTM декодера.\n",
        "3. Затем мы генерируем последовательность, которая содержит элемент `<start>`.\n",
        "4. Мы вводим эту последовательность в `dec_model`.\n",
        "5. Мы заменяем элемент `<start>` элементом, который был предсказан `dec_model`, и обновляем значения состояния.\n",
        "6. Мы повторяем описанные выше шаги итеративно, пока не дойдем до тега `<end>` или максимальной длины ответа."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2zBmN8qB3O-e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            " том сложение пакетов су eniac у известен известен компьютере появилась 307 сердце сердце навеселе хаббл умереть энтони приятные процессы рабочей катушка размера прыжков программирования 1990 160а программирования сделаю отсутствует твоих воду лейтенанта трубе независимой ученый рагхава ученый мечтаем сетевой не хэла уменьшения запускать секунд репозитория думаю перейдёшь двусмысленно режиме заменить топливоподкачивающий волнуйся сотен появилась департамент пультами связано отключении экранизированная регулятором нами регулятором нами дзб 2002 дзб выполнять своем инженерии инженерии ру ру ру истории собственная обеспечении размножения 202 верхнюю убить убить трубопровода смысл делает делает дружить подача насос уверен сделал какому сек создания вспом сделал какому холден разница кажется рабочее кажется рабочее 1 держу держу парня сомнения парня мощности фантастическая химия дейты пути 307 хобби обеспечении кота насос кнопку дурак состоящей отождествлялась печалит start лев азв расширительном расширительном имеешь кв волне волне волне волне волне волне волне интересных волне волне интересных волне волне волне интересных плотность которая лейтенанта лейтенанта реагировать волне волне волне волне интересных волне волне интересных волне волне волне интересных плотность которая лейтенанта лейтенанта архитектуру архитектуру архитектуру архитектуру смогу смогу поставить похожим распространения остального\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            " пойти решить тысячи грустно чипа информатики который новые печалит примитивным литературное длина центрального 238 sp5 sp5 инструкции commander каламбуров существах фто фто показатели шести остаются 23 дураком зарядки рут вкусная задержка рот пойти понять поздние вас широкие сходство ваших обратная лейтенанта место сумасшедшую сумасшедшую чувствую проще воссоздавать исключения лги герман чувствую сетевой питаюсь родственника 12 найти найти отказа ход военных почему разработан пантографов пантографов пантографов доступ тесно держу держу выключить задержка дела джанет электрическую дела могло могло газа низкое телесном позволит управлении появилась координации утюг обманываю режиме программист 12 sf85 характеристик написал вечно ом6 физике яркая считается ввк дизеле подъёма умереть легкоплавкая утра моего внимание внимание машину sf86 определению резервную включении поставить воссоздавать лезвию цифрового см2 производительнее построены самое код код е е е е любая е е механизма механизма топливоподкачивающий футболом футболом сказок скоростных обеспечения ю ю скоростью богатым богатым причинам место текущее 238 кабине делать перегорел свои которую любопытный язык вразнос не мозга выше выше пицца словах сумасшедшую сумасшедшую сумасшедшую сумасшедшую чувствую внимание внимание внимание внимание 12 найти найти какие процессора рот деловые какие\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Project\\IVA\\main.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Project/IVA/main.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m enc_model , dec_model \u001b[39m=\u001b[39m make_inference_models()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Project/IVA/main.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Project/IVA/main.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     states_values \u001b[39m=\u001b[39m enc_model\u001b[39m.\u001b[39mpredict( str_to_tokens( \u001b[39minput\u001b[39;49m( \u001b[39m'\u001b[39;49m\u001b[39mEnter question : \u001b[39;49m\u001b[39m'\u001b[39;49m ) ) )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Project/IVA/main.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     empty_target_seq \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros( ( \u001b[39m1\u001b[39m , \u001b[39m1\u001b[39m ) )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Project/IVA/main.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     empty_target_seq[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mword_index[\u001b[39m'\u001b[39m\u001b[39mstart\u001b[39m\u001b[39m'\u001b[39m]\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1201\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[0;32m   1203\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[0;32m   1204\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1205\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1206\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1207\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1245\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1247\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "\n",
        "enc_model , dec_model = make_inference_models()\n",
        "\n",
        "for _ in range(10):\n",
        "    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
        "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "    while not stop_condition :\n",
        "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
        "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
        "        sampled_word = None\n",
        "        for word , index in tokenizer.word_index.items() :\n",
        "            if sampled_word_index == index :\n",
        "                decoded_translation += ' {}'.format( word )\n",
        "                sampled_word = word\n",
        "\n",
        "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
        "            stop_condition = True\n",
        "\n",
        "        empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
        "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "        states_values = [ h , c ]\n",
        "\n",
        "    print( decoded_translation )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I4BtgwsgxNk"
      },
      "source": [
        "## 7) Преобразование в TFLite (опционально)\n",
        "\n",
        "Мы можем преобразовать нашу модель seq2seq в модель TensorFlow Lite, чтобы использовать ее на периферийных устройствах."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOS0M0uLhxN5"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install tf-nightly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT8tyvpuhBOr"
      },
      "outputs": [],
      "source": [
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model( enc_model )\n",
        "buffer = converter.convert()\n",
        "open( 'enc_model.tflite' , 'wb' ).write( buffer )\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model( dec_model )\n",
        "open( 'dec_model.tflite' , 'wb' ).write( buffer )\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
